{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse RSS Feeds and Write a Hugo markdown post automatically.\n",
    "\n",
    "This script was written to automatically parse my blog feed and write it into a YAML based markdown file so I could run a Hugo based web site easier. The only requirementa are to use Feedparser and Pandas which you can install by doing 'pip install feedparser' and 'pip install pandas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Uncomment this line if you want to install feedparser and pandas'''\n",
    "#!pip install feedparser\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import feedparser\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the markdown post write directory\n",
    "mydir = '/Users/thomasott/Dropbox/hugo/deoxy.xyz/content/items/' #put the directory where you want to save the YAML based .md files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the Feed\n",
    "myfeed = feedparser.parse('https://neuralmarkettrends.com/index.xml') #Put your own feed here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the parsed feed\n",
    "The following are just some internal checks to make sure the feed was parsed correctly. \n",
    "Some feeds may use 'date' vs 'publised' or other things that could cause this scrip to break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeed.entries[10].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeed.entries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeed.entries[10].published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeed.entries[10].link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = urlparse(myfeed.entries[10].link).hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (myfeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeed.entries[10].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "entry = len(myfeed)\n",
    "\n",
    "for i in range(entry):\n",
    "    j = 0\n",
    "    try:\n",
    "        tmp = (myfeed.entries[i].title, myfeed.entries[i].published, myfeed.entries[i].link, urlparse(myfeed.entries[i].link).hostname, \n",
    "           myfeed.entries[i].tags[j].term)\n",
    "    except:\n",
    "        tmp = (myfeed.entries[i].title, myfeed.entries[i].published, myfeed.entries[i].link, urlparse(myfeed.entries[i].link).hostname, \n",
    "           'untagged')\n",
    "    output.append(tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output, columns=['Title', 'Date', 'ItemURL', 'Sites', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make your exclusions here\n",
    "df = df[df.Sites != 'twitter.com']\n",
    "df = df[df.Sites != 'medium.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Regex to strip any tags if they're in the in the wrong format\n",
    "# Added a REGEX fix for Titles that could cause Hugo not to parse the file. \n",
    "\n",
    "import re\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    row['Tags'] = re.sub(\"\\s+\", \",\", row['Tags'].strip())\n",
    "    row['Title'] = re.sub(\"/\", \"-\", row['Title'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Title\"].apply(lambda x:x not in ['Untitled'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    with open(mydir+row['Title']+'.md', 'w') as f:\n",
    "        f.write('--- \\ntitle: \"'+row['Title']+'\"\\n'+\n",
    "                'date: '+row['Date']+'\\n'+\n",
    "                'itemurl: \"'+row['ItemURL']+'\"\\n'+\n",
    "                'sites: \"'+row['Sites']+'\"\\n'+\n",
    "                'tags: ['+row['Tags']+']\\n'+\n",
    "                '---')\n",
    "        \n",
    "        #f.write('---\\n', 'title:', row['Title'], '\\n', 'date:', row['Date'], '\\n', 'itemurl:', row['ItemURL'], '\\n', 'sites:', row['Sites'], 'summary:', row['Summary'], '\\n', '---'))\n",
    "        #print('---\\n', 'title:', row['Title'], '\\n', 'date:', row['Date'], '\\n', 'itemurl:', row['ItemURL'], '\\n', 'sites:', row['Sites'], 'summary:', row['Summary'], '\\n', '---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
